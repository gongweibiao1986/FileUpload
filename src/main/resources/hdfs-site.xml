<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
     <!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->
    <property>
            <name>dfs.nameservices</name>
            <value>ns1</value>
    </property>
    <!-- ns1下面有两个NameNode，分别是nn1，nn2 -->
    <property>
            <name>dfs.ha.namenodes.ns1</name>
            <value>nn1,nn2</value>
    </property>
    <!-- nn1的RPC通信地址 -->
    <property>
            <name>dfs.namenode.rpc-address.ns1.nn1</name>
            <value>bigdata01:9000</value>
    </property>
    <!-- nn1的http通信地址 -->
    <property>
            <name>dfs.namenode.http-address.ns1.nn1</name>
            <value>bigdata01:50070</value>
    </property>
    <!-- nn2的RPC通信地址 -->
    <property>
            <name>dfs.namenode.rpc-address.ns1.nn2</name>
            <value>bigdata02:9000</value>
    </property>
    <!-- nn2的http通信地址 -->
    <property>
            <name>dfs.namenode.http-address.ns1.nn2</name>
            <value>bigdata02:50070</value>
    </property>


 <!-- 指定NameNode的元数据在JournalNode上的存放位置 -->
    <property>
            <name>dfs.namenode.shared.edits.dir</name>
            <value>qjournal://bigdata01:8485;bigdata02:8485;bigdata03:8485/ns1</value>
    </property>
    <!-- 指定JournalNode在本地磁盘存放数据的位置 -->
    <property>
            <name>dfs.journalnode.edits.dir</name>
            <value>/home/data/hadoop/zk/journaldata</value>
    </property>
    <!-- 开启NameNode失败自动切换 -->
    <property>
            <name>dfs.ha.automatic-failover.enabled</name>
            <value>true</value>
    </property>
    <!-- 配置失败自动切换实现方式 -->
    <property>
            <name>dfs.client.failover.proxy.provider.ns1</name>
            <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->
    <property>
            <name>dfs.ha.fencing.methods</name>
            <value>
                    sshfence
                    shell(/bin/true)
            </value>
    </property>
    <!-- 使用sshfence隔离机制时需要ssh免登陆 -->
    <property>
            <name>dfs.ha.fencing.ssh.private-key-files</name>
            <value>/root/.ssh/id_rsa</value>
    </property>
    <!-- 配置sshfence隔离机制超时时间 -->
    <property>
            <name>dfs.ha.fencing.ssh.connect-timeout</name>
            <value>30000</value>
    </property>
    <!-- DataNode进程死亡或者网络故障造成DataNode无法与NameNode通信，NameNode不会
             立即把该节点判定为死亡，要经过一段超时时间。HDFS默认的超时时间是10分钟+30秒，如果定
    义超时时间为timeout，则其计算公式为：
    timeout = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval -->
    <property>
            <name>heartbeat.recheck.interval</name>
            <!-- 单位：毫秒 -->
            <value>2000</value>
    </property>
    <property>
            <name>dfs.heartbeat.interval</name>
            <!-- 单位：秒 -->
            <value>1</value>
    </property>
    <!-- 在日常维护hadoop集群过程中会发现这样一种现象：某个节点由于网络故障或者
             DataNode进程死亡，被NameNode判定为死亡，HDFS马上自动开始数据块的容错拷贝，
    当该节点重新加入到集群中，由于该节点的数据并没有损坏，导致集群中某些block的
    备份数超过了设定数值。默认情况下要经过1个小时的时间才会对这些冗余block进行清理。
    而这个时长与数据块报告时间有关。DataNode会定期将该节点上的所有block信息报告给
    NameNode，默认间隔1小时。下面的参数可以修改报告时间 -->
    <property>
            <name>dfs.blockreport.intervalMsec</name>
            <value>10000</value>
            <description>Determines block reporting interval in milliseconds.</description>
    </property>
    <!--指定磁盘预留多少空间，防止磁盘被撑满用完，单位为bytes -->
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>10240000</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>bigdata03:50090</value>
    </property>
    <property>
        <name>dfs.name.dir</name>
        <value>/home/data/hadoop/dfs/name</value>
        <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs
            persistently.
        </description>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>/home/data/hadoop/dfs/data</value>
        <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its
            blocks.
        </description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.permissions</name>
        <value>true</value>
        <description>need not permissions</description>
    </property>
    <!--NameNode有一个工作线程池用来处理客户端的远程过程调用及集群守护进程的调用。处理程序数量越多意味着要更大的池来处理来自不同DataNode的并发心跳以及客户端并发的元数据操作。对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。设置该值的一般原则是将其设置为集群大小的自然对数乘以20，即20logN，N为集群大小。
如果该值设的太小，明显的状况就是DataNode在连接NameNode的时候总是超时或者连接被拒绝，但NameNode的远程过程调用队列很大时，远程过程调用延时就会加大。症状之间是相互影响的，很难说修改dfs.namenode.handler.count就能解决问题，但是在查找故障时，检查一下该值的设置是必要的-->
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>35</value>
        <description>The number of server threads for the datanode.</description>
    </property>
    <!--读超时时间：dfs.client.socket-timeout。默认值1分钟。
    写超时时间：dfs.datanode.socket.write.timeout。默认8分钟。-->
    <property>
        <name>dfs.client.socket-timeout</name>
        <value>600000</value>
    </property>
    <property>
        <!--这里设置Hadoop允许打开最大文件数，默认4096，不设置的话会提示xcievers exceeded错误-->
        <name>dfs.datanode.max.transfer.threads</name>
        <value>409600</value>
    </property>
    <!---块大小-->

    <property>
        <name>dfs.blocksize</name>
        <value>134217728</value>
        <description>node2文件系统HDFS块大小为128M</description>
    </property>
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>

</configuration>

